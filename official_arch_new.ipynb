{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZBwzSzyS4sgDbWXeDk1Yk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Mount Google Drive"],"metadata":{"id":"TlVNirAcTYp2"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"7jw5gy93TV8m","executionInfo":{"status":"ok","timestamp":1727728110099,"user_tz":-120,"elapsed":3993,"user":{"displayName":"Sarra Bouzayane","userId":"07383484226530472524"}},"outputId":"121d0dad-676c-49f8-8796-741ca11f275c","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# from google.colab import drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#Set up dependencies"],"metadata":{"id":"JrSsp0LpTd-P"}},{"cell_type":"code","source":["!pip install einops\n","!pip install --upgrade --no-cache-dir gdown\n","!pip install --upgrade --no-cache-dir xlrd\n","!pip install av --upgrade --no-cache-dir xlrd\n","!pip install torchvision\n","!pip install torchvideo\n","!pip install timm"],"metadata":{"id":"fKeQiaErThPA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Import the necessary packages"],"metadata":{"id":"o_1tf096Tiy5"}},{"cell_type":"code","source":["import sys\n","import os\n","\n","#get the absolute path of the current directory\n","current_dir = os.path.abspath(os.path.dirname(__file__))\n","\n","#add the paths of the folders containing 'data' and 'config_' to sys.path\n","sys.path.append(os.path.join(current_dir, 'PFE-HAR-master'))\n","sys.path.append(os.path.join(current_dir, 'PFE-HAR-master', 'data'))\n","sys.path.append(os.path.join(current_dir, 'PFE-HAR-master', 'config_'))\n","sys.path.append(os.path.join(current_dir, 'train_dataset'))\n"],"metadata":{"id":"_1jQSIrQTks3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import os\n","from torch import nn, einsum\n","from einops import rearrange\n","from einops.layers.torch import Rearrange\n","from einops import repeat\n","from einops.layers.torch import Reduce\n","import numpy as np\n","import pandas as pd\n","import torchvision\n","import subprocess\n","import time\n","import sys\n","import importlib\n","import time\n","\n","import config_ as cfg\n","\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","\n","\n","cfg.DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device being used:\", cfg.DEVICE)\n","\n","torch.autograd.set_detect_anomaly(False)\n","torch.autograd.profiler.profile(False)\n","torch.autograd.profiler.emit_nvtx(False)\n","torch.backends.cudnn.benchmark = True"],"metadata":{"id":"XyymK8AtTos9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Check Directory Functions"],"metadata":{"id":"m_HCr63nTpUr"}},{"cell_type":"code","source":["def count_files_in_directory(directory):\n","    try:\n","        files = os.listdir(directory)\n","        num_files = len(files)\n","        return num_files\n","    except FileNotFoundError:\n","        print(f\"Error: Directory '{directory}' not found.\")\n","        return 0\n","\n","DIRECTORY_PATH = ''\n","\n","num_files = count_files_in_directory(DIRECTORY_PATH)\n","print(f\"Total number of files in directory '{DIRECTORY_PATH}': {num_files}\")"],"metadata":{"id":"azTJkdoeTrae"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Config Section"],"metadata":{"id":"kCFZmPHETs_W"}},{"cell_type":"code","source":["cfg.IMG_SIZE = 224\n","cfg.BATCH_SIZE = 4\n","cfg.DIM = 512\n","cfg.FPS = 30\n","cfg.DATA_PATH = \"./train_dataset\"\n","cfg.NUM_WORKERS = 0\n","cfg.PIN_MEMORY = False\n","cfg.IS_TRAIN = True\n","cfg.NB_EPOCHES = 100\n","\n","cfg.BLOCKS_DIM = [64, 128, 512, 512]\n","#cfg.DEVICE = \"cuda:0\"\n","cfg.DROP_OUT = 0.5\n","cfg.DROP_PATH = 0.5\n","cfg.MLP_RATIO = 4.\n","cfg.NUM_CLASSES = 41\n","\n","cfg.LEARNING_RATE = 0.001\n","cfg.WEIGHT_DECAY = 0.0005\n","\n","cfg.MODEL_PATH = \"\"\n","\n","cfg.DATASET_NAME = ''\n","\n","if cfg.DATASET_NAME == 'NTU_RGB_D_60':\n","    cfg.DATA_DIR = os.path.join(cfg.DATA_PATH, 'NTU_RGB_D_60/RGB_videos/nturgb+d_rgb')\n","    cfg.LABELS_DIR = os.path.join(cfg.DATA_PATH, 'NTU_RGB_D_60/Labels/labels')\n","    cfg.ACTIONS_File = os.path.join(cfg.DATA_PATH, 'NTU_RGB_D_60/Actions.xlsx')\n","elif cfg.DATASET_NAME == 'PKU_MMD_1':\n","    cfg.DATA_DIR = os.path.join(cfg.DATA_PATH, 'PKU_MMD_1/Data/RGB_videos')\n","    cfg.LABELS_DIR = os.path.join(cfg.DATA_PATH, 'PKU_MMD_1/Data/Labels/labels')\n","    cfg.ACTIONS_File = os.path.join(cfg.DATA_PATH, 'PKU_MMD_1/Data/Labels/labels/Actions.xlsx')\n","elif cfg.DATASET_NAME == 'PKU_MMD_2':\n","    cfg.DATA_DIR = os.path.join(cfg.DATA_PATH, 'PKU_MMD_2/Data/RGB_videos/RGB_VIDEO_v2')\n","    cfg.LABELS_DIR = os.path.join(cfg.DATA_PATH, 'PKU_MMD_2/Data/Labels/labels')\n","    cfg.ACTIONS_File = os.path.join(cfg.DATA_PATH, 'PKU_MMD_2/Data/Labels/labels/Actions.xlsx')\n","elif cfg.DATASET_NAME == 'HMDB51':\n","    DATA_DIR = os.path.join(cfg.DATA_PATH, 'HMDB51/videos')\n","    LABELS_FILE = os.path.join(cfg.DATA_PATH, 'HMDB51/labels')\n","    ACTIONS_File = None  # You can configure an actions file if needed\n","\n","elif cfg.DATASET_NAME == 'UCF101':\n","    DATA_DIR = os.path.join(cfg.DATA_PATH, 'UCF101/videos')\n","    LABELS_FILE = os.path.join(cfg.DATA_PATH, 'UCF101/labels')\n","    ACTIONS_File = None  # You can configure an actions file if needed\n","\n","elif cfg.DATASET_NAME == 'ETRI3D':\n","    DATA_DIR = os.path.join(cfg.DATA_PATH, 'ETRI3D/videos')\n","    LABELS_FILE = None  # Ensure your DataLoader handles this configuration\n","    ACTIONS_File = None  # You can configure an actions file if needed\n","else:\n","    raise ValueError(f\"Unknown dataset: {cfg.DATASET_NAME}\")"],"metadata":{"id":"6TSeChWuTu53"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Empty Cash Call"],"metadata":{"id":"ioRTnx7vTxUd"}},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"rleLHUWVTzHp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Load Data"],"metadata":{"id":"X4OW5DDvT1C1"}},{"cell_type":"code","source":["import data.new_datasets\n","importlib.reload(data.new_datasets)\n","from data.new_datasets import PKUMMDPhase1Dataset, PKUMMDPhase2Dataset, NTURGBD60Dataset, HMDB51Dataset, UCF101Dataset, ETRI3DDataset\n","from torch.utils.data import DataLoader, random_split\n","from data_loader import get_data_loader, collate_fn\n","# from data.data_loader import collate_fn\n","import time\n","from tqdm import tqdm"],"metadata":{"id":"I7B--kwCT4G3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Charger les données\n","subset_size = 500\n","try:\n","    all_data = get_data_loader(cfg.DATASET_NAME, cfg.DATA_DIR, cfg.LABELS_DIR, cfg.ACTIONS_File, batch_size=cfg.BATCH_SIZE, transform=transform, mode='all', subset_size=subset_size, collate_fn=collate_fn, img_size=cfg.IMG_SIZE)\n","except Exception as e:\n","    print(f\"Error loading data: {e}\")\n","    raise\n","\n","if len(all_data.dataset) == 0:\n","    raise ValueError(\"No data loaded. Check file paths and dataset configurations.\")"],"metadata":{"id":"hkyiwlQvT-zV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Divide data into train and test data"],"metadata":{"id":"6tb8T9M9Y4AT"}},{"cell_type":"code","source":["#define the sizes for training and testing datasets\n","train_size = int(0.7 * len(all_data.dataset))  # 70% pour l'entraînement\n","test_size = len(all_data.dataset) - train_size  # 30% pour le test\n","\n","#split the data into training and testing datasets\n","train_dataset, test_dataset = random_split(all_data.dataset, [train_size, test_size])\n","\n","#create DataLoaders for training and testing\n","train_loader = DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n","\n","print(f\"Nombre total de vidéos pour l'entraînement : {len(train_dataset)}\")\n","print(f\"Nombre total de vidéos pour le test : {len(test_dataset)}\")"],"metadata":{"id":"m2BsqVI2YueR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Construct the Model"],"metadata":{"id":"9iHuuOGvT_cM"}},{"cell_type":"code","source":["from model import Model\n","\n","# Construct the model\n","if cfg.MODEL_PATH == \"\":\n","    print(\"============== Construct The Model ========\")\n","    model = Model(cfg.NUM_CLASSES).to(cfg.DEVICE)\n","else:\n","    print(\"============== Load The Model ========\")\n","    model = torch.load(cfg.MODEL_PATH).to(cfg.DEVICE)\n","\n","torch.cuda.empty_cache()"],"metadata":{"id":"xK7UW3LnUCP1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Train - Test"],"metadata":{"id":"_yLDWiFBUFSg"}},{"cell_type":"code","source":["from train_evaluate import TrainAndEvaluate\n","\n","# Train\n","if cfg.MODEL_PATH == \"\":\n","    print(\"=========== Train ======== \\n\")\n","    loss_list, training_accuracy_list = trainAndEvaluate.train(train_loader, cfg.LEARNING_RATE, cfg.WEIGHT_DECAY,\n","                                                               intermediate_result_step=10, print_epoch_result_step=1)\n","    # Save the trained model\n","    trainAndEvaluate.save_model('./saved_model.pth')\n","    cfg.MODEL_PATH = './saved_model.pth'\n","else:\n","    print(\"=========== Evaluate ======== \\n\")\n","    # Evaluate the model on the test data\n","    trainAndEvaluate.test(test_loader, intermediate_result_step=10)\n"],"metadata":{"id":"WyMfokVkUJoZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Visualization"],"metadata":{"id":"DjmIMVYDUNHY"}},{"cell_type":"markdown","source":["##Import and Initialize the Visualization Class"],"metadata":{"id":"yn4d0T5eVLD1"}},{"cell_type":"code","source":["from visualization import Visualization\n","\n","# Initialiser l'objet de visualisation avec le modèle\n","visualization = Visualization(model)\n"],"metadata":{"id":"4Vxyg3cpUOOe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot the training loss curve\n","visualization.plot_loss(loss_list)\n"],"metadata":{"id":"zSIK3X1lVQ-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#select a video sample from the DataLoader\n","video_sample = next(iter(train_loader))[0][0]  # Get the first video sample from the training DataLoader\n"],"metadata":{"id":"Gpc4FOorVS18"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#visualize the raw video (before processing)\n","video_animation = visualization.plot_video(video_sample)\n","video_animation\n"],"metadata":{"id":"HAa2vKcNVT-A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#set hooks to capture intermediate activations\n","visualization.set_hooks()\n","\n","#perform a forward pass through the model to capture activations\n","visualization.perform_forward(video_sample)\n"],"metadata":{"id":"rwDY7lvmVWmy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#visualize the output of the first CNN layer\n","visualization.plot_first_cnn_layer()\n"],"metadata":{"id":"IkTPO-l1VZ9j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#visualize the output of the spatial CNN block\n","spatial_bloc_animation = visualization.plot_spatial_bloc_output()\n","spatial_bloc_animation\n"],"metadata":{"id":"upfJoWgrVduK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#visualize the attention effect as a heatmap overlaid on the original video\n","attention_animation = visualization.plot_attention(video_sample)\n","attention_animation\n"],"metadata":{"id":"xfTfWwsOVf-l"},"execution_count":null,"outputs":[]}]}